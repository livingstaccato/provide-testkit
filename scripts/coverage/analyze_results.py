#!/usr/bin/env python3
# SPDX-FileCopyrightText: Copyright (c) 2025 provide.io llc. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#

"""Parse pytest log files and generate a comprehensive report.

This script analyzes pytest output logs generated by run_tests.sh and creates
a comprehensive coverage and test results report.

Usage:
    python analyze_results.py [LOG_DIR]

Arguments:
    LOG_DIR - Directory containing .log files (default: <tempdir>/pytest-logs)

Output:
    - Console: Formatted report with summary table and observations
    - File: REPORT.txt in the LOG_DIR

Features:
    - Parses test counts (passed/failed/skipped)
    - Extracts coverage percentages (line and branch coverage)
    - Identifies failed tests
    - Generates summary statistics
    - Highlights high/low performers"""

import re
import sys
import tempfile
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

@dataclass
class TestResult:
    package: str
    passed: int = 0
    failed: int = 0
    skipped: int = 0
    warnings: int = 0
    errors: list[str] = None
    coverage_line: Optional[float] = None
    coverage_branch: Optional[float] = None
    total_coverage: Optional[float] = None
    execution_time: Optional[str] = None
    status: str = "UNKNOWN"

    def __post_init__(self):
        if self.errors is None:
            self.errors = []

    @property
    def total_tests(self) -> int:
        return self.passed + self.failed + self.skipped

    @property
    def pass_rate(self) -> float:
        if self.total_tests == 0:
            return 0.0
        return (self.passed / self.total_tests) * 100


def parse_log_file(log_path: Path) -> TestResult:
    """Parse a single pytest log file."""
    package = log_path.stem
    result = TestResult(package=package)

    content = log_path.read_text()

    # Strip ANSI color codes
    ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    content = ansi_escape.sub('', content)

    # Check for errors
    if "ERROR:" in content or "INTERNALERROR" in content:
        error_lines = [line for line in content.split('\n') if 'ERROR' in line]
        result.errors.extend(error_lines[:5])  # First 5 errors
        if "Cannot change to directory" in content or "No such file" in content:
            result.status = "NO_TESTS"
            return result

    # Check if no tests directory exists
    if "no tests ran" in content.lower() or "no test" in content.lower():
        result.status = "NO_TESTS"
        return result

    # Parse test summary line
    # Formats: "===== 1 failed, 5737 passed, 75 skipped, 48 warnings in 209.24s ====="
    #          "======== 34 failed, 992 passed, 3 skipped, 1 error in 93.71s ========"
    #          "======================== 82 passed in 65.01s ========================="
    #          "==================== 128 passed, 2 skipped in 61.40s ===================="
    # Look for the pattern with passed/failed/skipped/errors
    summary_pattern = r'=+\s*(?:(\d+)\s+(?:failed|error)s?[,\s]+)?(?:(\d+)\s+passed)?(?:[,\s]+(\d+)\s+skipped)?.*?\s+in\s+([\d:.]+s)'
    summary_match = re.search(summary_pattern, content, re.IGNORECASE)

    if summary_match:
        result.failed = int(summary_match.group(1) or 0)
        result.passed = int(summary_match.group(2) or 0)
        result.skipped = int(summary_match.group(3) or 0)
        result.execution_time = summary_match.group(4)

        if result.failed > 0:
            result.status = "FAILED"
        elif result.passed > 0:
            result.status = "PASSED"

    # Parse coverage (look for "Total coverage: XX.XX%")
    total_cov_pattern = r'Total coverage:\s*([\d.]+)%'
    total_cov_match = re.search(total_cov_pattern, content)
    if total_cov_match:
        result.total_coverage = float(total_cov_match.group(1))

    # Parse detailed coverage from coverage report
    # Look for TOTAL line: "TOTAL   1234  567   89%   45%" or "TOTAL  3558    149   1496    125    94%"
    # Format can be: TOTAL <stmts> <miss> <coverage%> [<branch%>]
    # Or with branch: TOTAL <stmts> <miss> <branch> <partial> <coverage%>
    coverage_total_pattern = r'TOTAL\s+\d+\s+\d+(?:\s+\d+)?(?:\s+\d+)?\s+([\d.]+)%'
    cov_match = re.search(coverage_total_pattern, content)
    if cov_match:
        result.coverage_line = float(cov_match.group(1))

    # Extract failed test names
    failed_pattern = r'FAILED ([\w/.:-]+)'
    failed_tests = re.findall(failed_pattern, content)
    if failed_tests:
        result.errors.extend([f"FAILED: {test}" for test in failed_tests[:5]])

    return result


def generate_report(results: list[TestResult]) -> str:
    """Generate a comprehensive text report."""
    report = []
    report.append("=" * 100)
    report.append("PYTEST COVERAGE REPORT - ALL PACKAGES")
    report.append("=" * 100)
    report.append("")

    # Summary table
    report.append("SUMMARY TABLE")
    report.append("-" * 100)
    header = f"{'Package':<25} {'Status':<12} {'Tests':<15} {'Pass Rate':<12} {'Coverage':<12} {'Time':<12}"
    report.append(header)
    report.append("-" * 100)

    for r in sorted(results, key=lambda x: x.package):
        status_emoji = {
            "PASSED": "✓",
            "FAILED": "✗",
            "NO_TESTS": "○",
            "UNKNOWN": "?"
        }.get(r.status, "?")

        tests_str = f"{r.passed}P/{r.failed}F/{r.skipped}S" if r.total_tests > 0 else "N/A"
        pass_rate_str = f"{r.pass_rate:.1f}%" if r.total_tests > 0 else "N/A"

        cov_str = "N/A"
        if r.total_coverage:
            cov_str = f"{r.total_coverage:.2f}%"
        elif r.coverage_line:
            if r.coverage_branch:
                cov_str = f"{r.coverage_line:.1f}%/{r.coverage_branch:.1f}%"
            else:
                cov_str = f"{r.coverage_line:.1f}%"

        time_str = r.execution_time or "N/A"

        line = f"{r.package:<25} {status_emoji} {r.status:<10} {tests_str:<15} {pass_rate_str:<12} {cov_str:<12} {time_str:<12}"
        report.append(line)

    report.append("-" * 100)
    report.append("")

    # Overall statistics
    total_passed = sum(r.passed for r in results)
    total_failed = sum(r.failed for r in results)
    total_skipped = sum(r.skipped for r in results)
    total_tests = total_passed + total_failed + total_skipped

    packages_with_tests = [r for r in results if r.total_tests > 0]
    avg_coverage = sum(r.total_coverage or r.coverage_line or 0 for r in packages_with_tests) / len(packages_with_tests) if packages_with_tests else 0

    report.append("OVERALL STATISTICS")
    report.append("-" * 100)
    report.append(f"Total Packages: {len(results)}")
    report.append(f"Packages with Tests: {len(packages_with_tests)}")
    report.append(f"Total Tests: {total_tests}")
    report.append(f"  - Passed: {total_passed}")
    report.append(f"  - Failed: {total_failed}")
    report.append(f"  - Skipped: {total_skipped}")
    report.append(f"Overall Pass Rate: {(total_passed/total_tests*100):.2f}%" if total_tests > 0 else "N/A")
    report.append(f"Average Coverage: {avg_coverage:.2f}%")
    report.append("")

    # Detailed results
    report.append("=" * 100)
    report.append("DETAILED RESULTS")
    report.append("=" * 100)
    report.append("")

    for r in sorted(results, key=lambda x: x.package):
        report.append(f"\n### {r.package.upper()} ###")
        report.append(f"Status: {r.status}")
        report.append(f"Tests: {r.passed} passed, {r.failed} failed, {r.skipped} skipped")

        if r.coverage_line:
            cov_str = f"Coverage: Line {r.coverage_line:.1f}%"
            if r.coverage_branch:
                cov_str += f", Branch {r.coverage_branch:.1f}%"
            report.append(cov_str)
        if r.total_coverage:
            report.append(f"Total Coverage: {r.total_coverage:.2f}%")

        if r.execution_time:
            report.append(f"Execution Time: {r.execution_time}")

        if r.errors:
            report.append("Errors/Failed Tests:")
            for error in r.errors[:10]:
                report.append(f"  - {error}")

        report.append("")

    # Observations
    report.append("=" * 100)
    report.append("OBSERVATIONS")
    report.append("=" * 100)
    report.append("")

    # Packages without tests
    no_tests = [r for r in results if r.status == "NO_TESTS"]
    if no_tests:
        report.append(f"⚠️  Packages without tests ({len(no_tests)}):")
        for r in no_tests:
            report.append(f"  - {r.package}")
        report.append("")

    # Failed packages
    failed = [r for r in results if r.status == "FAILED"]
    if failed:
        report.append(f"❌ Packages with failures ({len(failed)}):")
        for r in failed:
            report.append(f"  - {r.package}: {r.failed} failed tests")
        report.append("")

    # Low coverage packages (< 70%)
    low_cov = [r for r in packages_with_tests if (r.total_coverage or r.coverage_line or 100) < 70]
    if low_cov:
        report.append(f"⚠️  Packages with low coverage (<70%) ({len(low_cov)}):")
        for r in low_cov:
            cov = r.total_coverage or r.coverage_line or 0
            report.append(f"  - {r.package}: {cov:.1f}%")
        report.append("")

    # High performers
    high_perf = [r for r in packages_with_tests
                 if r.status == "PASSED"
                 and (r.total_coverage or r.coverage_line or 0) >= 80]
    if high_perf:
        for r in sorted(high_perf, key=lambda x: -(x.total_coverage or x.coverage_line or 0)):
            cov = r.total_coverage or r.coverage_line or 0
            report.append(f"  - {r.package}: {cov:.1f}% coverage, {r.total_tests} tests")
        report.append("")

    return "\n".join(report)


def main():
    # Allow log directory to be specified via command line
    default_log_dir = Path(tempfile.gettempdir()) / "pytest-logs"
    log_dir_arg = sys.argv[1] if len(sys.argv) > 1 else str(default_log_dir)
    log_dir = Path(log_dir_arg)

    if not log_dir.exists():
        print(f"Error: Log directory not found: {log_dir}")
        sys.exit(1)

    log_files = sorted(log_dir.glob("*.log"))

    results = []
    for log_file in log_files:
        result = parse_log_file(log_file)
        results.append(result)

    report = generate_report(results)

    # Print to stdout
    print(report)

    # Save to file
    report_file = log_dir / "REPORT.txt"
    report_file.write_text(report)
    print(f"\n\nReport saved to: {report_file}")


if __name__ == "__main__":
    main()

# 🧪✅🔚
